1001 miles
============  

Python VM main loop
---------------------------

Python如何处理Exception
-----------------------------

自制极简socket模块
--------------------------------
socket是python网络通信的主要模块，它实际上只是_socket的一个简单wrap。通过分析_socket模块的
源码 Modules/socketmodule.c，可以加深对python socket工作原理的理解。

这个文件有5000多行，如果我们只想要最基本的网络功能，建立连接，接收，发送tcp数据，别的
如ipv6，gethostby*, inet_*等辅助性函数都不需要，也不用考虑平台可移植性，这样一个
极简的可以工作socket模块会是什么样子呢?

注：本例中的代码几乎全部copy自socketmodule.c

完整代码: https://github.com/nkchenz/cpythonjourney/blob/sockmini/Modules/socketmini.c

_sockmini模块
~~~~~~~~~~~~~~~~~~
我们的新模块为_sockmini，将使用一个新的类型sockmini来标识自定义的socket对象， 对应关系:
_socket -> _sockmini, _socket.socket -> _sockmini.sockmini

新建文件 Modules/socketmini.c::

    static PyMethodDef sockmini_methods[] = {
        {"setdefaulttimeout",       socket_setdefaulttimeout,
         METH_O, setdefaulttimeout_doc},
        {NULL}  /* Sentinel */
    };

    PyMODINIT_FUNC
    init_sockmini(void) 
    {
        PyObject* m;

        m = Py_InitModule3("_sockmini", sockmini_methods, "sockmini module");
        if(m == NULL)
            return;

        /* The general exception type */
        socket_error = PyErr_NewException("_sockmini.error",
                                          PyExc_IOError, NULL);
        if(socket_error == NULL)
            return;
        Py_INCREF(socket_error);
        PyModule_AddObject(m, "error", socket_error);
     
        /* Add a new type to module */
        Py_TYPE(&sockmini_type) = &PyType_Type;
        Py_INCREF((PyObject *)&sockmini_type);
        if (PyModule_AddObject(m, "sockmini",
                               (PyObject *)&sockmini_type) != 0)
            return;
    }


_sockmini模块只有一个模块级方法socket_setdefaulttimeout，成员error类似于socket.error，用来设置异常，
另一个成员sockmini就是我们的新socket对象。

sockmini type
~~~~~~~~~~~~~~~~
sockmini和socket.socket类型使用同样的存储结构PySocketSockObject，这样很多函数参数的类型
都可以复用::

    static PyMethodDef sock_methods[] = {
        {"connect",           (PyCFunction)sock_connect, METH_O,
                          connect_doc},

        {"close",             (PyCFunction)sock_close, METH_NOARGS,
                          close_doc},
        {"recv",              (PyCFunction)sock_recv, METH_VARARGS,
                          recv_doc},
        {"send",              (PyCFunction)sock_send, METH_VARARGS,
                          send_doc},
        {NULL,                      NULL}           /* sentinel */
    };

    /* Type object for socket objects. */

    static PyTypeObject sockmini_type = {
        PyVarObject_HEAD_INIT(0, 0)         /* Must fill in type value later */
        "_sockmini.sockmini",                           /* tp_name */
        sizeof(PySocketSockObject),                 /* tp_basicsize */
        0,                                          /* tp_itemsize */
        (destructor)sock_dealloc,                   /* tp_dealloc */
        ...
        PyObject_GenericGetAttr,                    /* tp_getattro */
        ...
        sock_methods,                               /* tp_methods */
        ...
        sock_initobj,                               /* tp_init */
        PyType_GenericAlloc,                        /* tp_alloc */
        PyType_GenericNew,                          /* tp_new */
        PyObject_Del,                               /* tp_free */
    };

sockmini只有四个methods: connect，recv，send，close，底层的c struct是PySocketSockObject，
初始化函数 sock_initobj, 释放时调用sock_dealloc。

初始化和释放sock object
~~~~~~~~~~~~~~~~~~~~~~~~~~~
::

    static int
    sock_initobj(PyObject *self)
    {
        PySocketSockObject *s = (PySocketSockObject *)self;
        int fd;
        int family = AF_INET, type = SOCK_STREAM, proto = 0;

        Py_BEGIN_ALLOW_THREADS
        fd = socket(family, type, proto);
        Py_END_ALLOW_THREADS
        if (fd < 0) {
            PyErr_SetString(socket_error, "Failed to create socket");
            return -1;
        }

        s->sock_fd = fd;
        s->sock_family = family;
        s->sock_type = type;
        s->sock_proto = proto;

        /* Notes: Be carefull about the concept of timeout here
         *
         *  It only measures the time when a socket becomes ready to read or write, not the time
         *  took to send or read your data, alas, it's the max idle time spent on waiting,
         *  not the real busy io time
         * */
        s->sock_timeout = defaulttimeout;
        /* Set to non blocking if timeout is not negative */
        if (s->sock_timeout >= 0.0)
            set_blocking(s, 0);
        return 0;
    }

family，type，proto使用硬编码，仅支持tcp stream。创建sockmini对象时，默认使用defaulttimeout
全局变量，该变量可以通过模块函数 _sockmini.setdefaulttimeout 设置。默认值为-1，表示使用blocking fd。

sock_timeout的意义:

- 0.0 non-blocking mode
- > 0 timeout mode, 底层是non-blocking fd
- < 0 blocking mode

See http://docs.python.org/2/library/socket.html#socket.socket.settimeout

如果sockmini对象的超时时间>0，则要使用nonblocking的socket fd，这样底层的connect，send，
recv等c函数才不会一直等待，timeout才有意义。注意，这里的timeout是等待IO变成可用的时间，
而不是实际执行IO的时间，后面可以详细看到。

sock_dealloc 函数并没有什么修改。

connect, close
~~~~~~~~~~~~~~~~~~~~~
_socket模块的getsockaddrarg非常复杂，因为要解析各种各样的协议，而我们的_sockmini只用关心
tcp，就简单的多了::

    static int
    getsockaddrarg(PySocketSockObject *s, PyObject *args,
                   struct sockaddr *addr_ret, int *len_ret)
    {
        struct sockaddr_in* addr;
        char *host;
        int port, result;
        struct addrinfo hints, *res;
        size_t addr_ret_size;

        if (!PyArg_ParseTuple(args, "si:connect", &host, &port))
            return 0;

        addr=(struct sockaddr_in*)addr_ret;

        /* Getaddrinfo */
        memset(&hints, 0, sizeof(hints));
        hints.ai_family = AF_INET;
        Py_BEGIN_ALLOW_THREADS
        result = getaddrinfo(host, NULL, &hints, &res);
        Py_END_ALLOW_THREADS
        if (result) {
            PyErr_SetString(socket_error, "Failed to getaddrinfo ");
            return 0;
        }

        addr_ret_size = sizeof(*addr);
        if (res->ai_addrlen < addr_ret_size)
            addr_ret_size = res->ai_addrlen;
        memcpy((char *) addr, res->ai_addr, addr_ret_size);
        freeaddrinfo(res);

        addr->sin_family = AF_INET;
        addr->sin_port = htons((short)port);
        *len_ret = sizeof *addr;

        return 1;
    }

    /* s.connect(sockaddr) method */

    static PyObject *
    sock_connect(PySocketSockObject *s, PyObject *args)
    {
        sock_addr_t addrbuf;
        int addrlen;
        int res, timeout = 0;

        if (!getsockaddrarg(s, args, SAS2SA(&addrbuf), &addrlen))
            return NULL;

        Py_BEGIN_ALLOW_THREADS
        res = connect(s->sock_fd, SAS2SA(&addrbuf), addrlen);
        if (s->sock_timeout > 0.0) {
            // If timeout is given, use poll to check whether it's ready
            if (res < 0 && errno == EINPROGRESS) {
                timeout = poll_check(s, 1);
                if (timeout == 0) {
                    /* Bug #1019808: in case of an EINPROGRESS,
                       use getsockopt(SO_ERROR) to get the real
                       error. */
                    socklen_t res_size = sizeof res;
                    (void)getsockopt(s->sock_fd, SOL_SOCKET,
                                     SO_ERROR, &res, &res_size);
                    if (res == EISCONN)
                        res = 0;
                    errno = res;
                }
                else if (timeout == -1) {
                    res = errno;            /* had error */
                }
            }
        }
        Py_END_ALLOW_THREADS

        if (timeout == 1){
            PyErr_SetString(socket_error, "timed out");
            return NULL;
        }
        if (res != 0)
            return PyErr_SetFromErrno(socket_error);
        Py_INCREF(Py_None);
        return Py_None;
    }

connect的逻辑是这样的:

- 调用 getsockaddrarg 解析地址
- 底层connect
- 如果不是timeout mode，那么底层connect的结果就是我们要的结果
- 如果超时时间>0，意味着我们在connect一个non-blocking的socket fd，如果成功则一切OK。
  如果失败，那要看是不是真的失败了，可能只是inprogress，表示连接还在建立中，这时就要
  调用poll_check，等待连接变为可用再返回。#1019808的意思是，poll在non-blocking fd EINPROGRESS时
  也有可能返回0，需要特殊处理，查看具体状态。这里的逻辑比较复杂，可能还有问题。
- 错误处理

sock_close 没有修改。

timeout, poll_check
~~~~~~~~~~~~~~~~~~~~~~~~~
poll_check 超时检测，查看fd是否就绪。返回1则表示等待超时，-1错误发生，0 IO就绪或其他。

如果sock对象不处于timeout mode，即sock_timeout<=0.0，则无需检测超时。不执行任何操作，
立即返回0。只有timeout>0.0时，才会调用系统的poll，等待IO事件发生，该函数返回之后，
调用者就可以立即操作non-blocking的fd了。

::

    int poll_check(PySocketSockObject *s, int writing)
    {
        int n;

        struct pollfd pollfd;
        int timeout;

        // If in blocking mode, do nothing
        if (s->sock_timeout <= 0.0)
            return 0;

        pollfd.fd = s->sock_fd;
        pollfd.events = writing ? POLLOUT : POLLIN;

        /* s->sock_timeout is in seconds, timeout in ms */
        timeout = (int)(s->sock_timeout * 1000 + 0.5);
        n = poll(&pollfd, 1, timeout);
            
        /* Returns 1 on timeout, -1 on error, 0 otherwise. */
        if (n < 0)
            return -1;
        if (n == 0){
            return 1;
        }
        return 0;
    }

send, recv
~~~~~~~~~~~~~~~~~~
有了poll_check这个利器之后，真正的发送，接收函数反而比较简单。

sock_send 在发送数据前调用poll_check，非timeout mode下，poll_check什么也不做，一切交由
后续的send函数处理，blocking的fd有可能可能，non-blocking的fd则不会等待，符合上层的语义。

在timeout mode下，timeout>0.0，则poll_check最多等待timeout时间后返回。如果没超时也没出错
则为io就绪，后续send会一次发送尽可能多的数据，因为这是non-blocking fd, send不会等待。
timeout的实现借助non-blocking fd得以完成。需要注意，send发送数据的耗时并没有计算在timeout里，
timeout的意义仅限于IO等待超时。

当底层的send返回时，进行错误检查，用PyErr_SetFromErrno根据errno设置了合理的异常。

sock_recv 函数的逻辑与此类似。

::

    static PyObject *
    sock_send(PySocketSockObject *s, PyObject *args)
    {

        char *buf;
        int len, n = -1, flags = 0, timeout;
        Py_buffer pbuf;

        if (!PyArg_ParseTuple(args, "s*|i:send", &pbuf, &flags))
            return NULL;

        buf = pbuf.buf;
        len = pbuf.len;

        Py_BEGIN_ALLOW_THREADS
        timeout = poll_check(s, 1);
        if (!timeout) // no error and timeout
            n = send(s->sock_fd, buf, len, flags);
        Py_END_ALLOW_THREADS

        PyBuffer_Release(&pbuf);

        if (timeout == 1){
            PyErr_SetString(socket_error, "timed out");
            return NULL;
        }
        if (n < 0)
            return PyErr_SetFromErrno(socket_error);
        return PyInt_FromLong((long)n);
    }


    static PyObject *
    sock_recv(PySocketSockObject *s, PyObject *args)
    {
        int recvlen, flags = 0, timeout;
        ssize_t outlen;
        PyObject *buf;

        if (!PyArg_ParseTuple(args, "i|i:recv", &recvlen, &flags))
            return NULL;

        if (recvlen < 0) {
            PyErr_SetString(PyExc_ValueError,
                            "negative buffersize in recv");
            return NULL;
        }

        /* Allocate a new string. */
        buf = PyString_FromStringAndSize((char *) 0, recvlen);
        if (buf == NULL)
            return NULL;

        Py_BEGIN_ALLOW_THREADS
        timeout = poll_check(s, 0);
        if (!timeout) // no error and timeout
            outlen = recv(s->sock_fd, PyString_AS_STRING(buf), recvlen, flags);
        Py_END_ALLOW_THREADS

        if (timeout == 1){
            PyErr_SetString(socket_error, "timed out");
            return NULL;
        }
        if (outlen < 0) {
            /* An error occurred, release the string and return an
               error. */
            Py_DECREF(buf);
            return PyErr_SetFromErrno(socket_error);
        }
        if (outlen != recvlen) {
            /* We did not read as many bytes as we anticipated, resize the
               string if possible and be succesful. */
            if (_PyString_Resize(&buf, outlen) < 0)
                /* Oopsy, not so succesful after all. */
                return NULL;
        }

        return buf;
    }

注意，当send写入0个字节，recv读取到空字符串时，不一定表示错误。

综合下来，其实整个模块复杂的地方就在于对timeout的处理，其他都是对socket c编程的直接封装。

编译设置
~~~~~~~~~~~~~
修改setup.py，告诉make编译我们的_sockmini模块::

    diff --git a/setup.py b/setup.py
    index 6e02114..76b6afd 100644
    --- a/setup.py
    +++ b/setup.py
    @@ -689,6 +689,9 @@ class PyBuildExt(build_ext):
             # socket(2)
             exts.append( Extension('_socket', ['socketmodule.c'],
                                    depends = ['socketmodule.h']) )
    +        exts.append( Extension('_sockmini', ['socketmini.c'],
    +                               depends = ['socketmodule.h']) )
    +
             # Detect SSL support for the socket module (via _ssl)
             search_for_ssl_incs_in = [
                                   '/usr/local/ssl/include',

make ::

    13:59 jaime@oldtown 2.6.7 (sockmini)$ make
    running build
    running build_ext
    building '_sockmini' extension
    gcc -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I. -I/Users/jaime/source/2.6.7/./Include -I/Users/jaime/source/2.6.7/./Mac/Include -I. -IInclude -I./Include -I/usr/local/include -I/Users/jaime/source/2.6.7/Include -I/Users/jaime/source/2.6.7 -c /Users/jaime/source/2.6.7/Modules/socketmini.c -o build/temp.macosx-10.4-x86_64-2.6/Users/jaime/source/2.6.7/Modules/socketmini.o
    /Users/jaime/source/2.6.7/Modules/socketmini.c:389: warning: initialization from incompatible pointer type
    /Users/jaime/source/2.6.7/Modules/socketmodule.h:228: warning: ‘PySocketModule_ImportModuleAndAPI’ defined but not used
    gcc -bundle -undefined dynamic_lookup build/temp.macosx-10.4-x86_64-2.6/Users/jaime/source/2.6.7/Modules/socketmini.o -L/usr/local/lib -o build/lib.macosx-10.4-x86_64-2.6/_sockmini.so

    ...

    running build_scripts
    13:59 jaime@oldtown 2.6.7 (sockmini)$ 

测试代码
~~~~~~~~~~~~
::

    #import _socket as _sockmini
    #from _socket import socket as sockmini

    import _sockmini
    from _sockmini import sockmini

    _sockmini.setdefaulttimeout(3)

    s = sockmini()
    s.connect(('www.google.com', 80))
    #s.connect(('www.github.com', 80))
    #s.connect(('www.douban.com', 80))
    s.send('GET / HTTP/1.1\n\n')
    data = ''
    while 1:
        tmp = s.recv(4096)
        print '-', len(tmp), tmp
        if not tmp:
            break
        data += tmp
    print data


运行输出::

    10:41 jaime@oldtown 2.6.7 (sockmini)$ ./python.exe tests/test_sockmini.py 
    - 1279 HTTP/1.1 302 Found
      Location:
      http://www.google.com.hk/url?sa=p&hl=zh-CN&pref=hkredirect&pval=yes&q=http://www.google.com.hk/&ust=1353811295390764&usg=AFQjCNGq9Gh7aZ15wEgee3rdzZBwbYxXUQ
      Cache-Control: private
      Content-Type: text/html; charset=UTF-8
      Set-Cookie:
      PREF=ID=1adfb854d08d14e0:FF=0:NW=1:TM=1353811265:LM=1353811265:S=XEogFSHieh_DmFUd;
      ...
      Server: gws
      Content-Length: 376
      X-XSS-Protection: 1; mode=block
      X-Frame-Options: SAMEORIGIN

    <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
    <TITLE>302 Moved</TITLE></HEAD><BODY>
    <H1>302 Moved</H1>
    The document has moved
    <A
    HREF="http://www.google.com.hk/url?sa=p&amp;hl=zh-CN&amp;pref=hkredirect&amp;pval=yes&amp;q=http://www.google.com.hk/&amp;ust=1353811295390764&amp;usg=AFQjCNGq9Gh7aZ15wEgee3rdzZBwbYxXUQ">here</A>.
    </BODY></HTML>

Notes
~~~~~~~~~~
虽然比较简陋，而且可能还有很多问题，但是我们确实有了一个可以工作的socket模块，it's funny

cProfile
--------------

cProfile是python的性能测试模块，它只是_lsprof模块的一个封装，用来展示输出后者收集的数据。

运行profile实际上是在enable，disable Python VM的profiling功能。

Lib/cProfile.py::

    class Profile(_lsprof.Profiler):
        """Profile(custom_timer=None, time_unit=None, subcalls=True, builtins=True)

        ...
     
        def runctx(self, cmd, globals, locals):
            self.enable()
            try:
                exec cmd in globals, locals
            finally:
                self.disable()
            return self

Module/_lsprof.c::

    static PyObject*
    profiler_enable(ProfilerObject *self, PyObject *args, PyObject *kwds)
    {
        int subcalls = -1;
        int builtins = -1;
        static char *kwlist[] = {"subcalls", "builtins", 0};
        if (!PyArg_ParseTupleAndKeywords(args, kwds, "|ii:enable",
                                         kwlist, &subcalls, &builtins))
            return NULL;
        if (setSubcalls(self, subcalls) < 0 || setBuiltins(self, builtins) < 0)
            return NULL;
        PyEval_SetProfile(profiler_callback, (PyObject*)self);
        self->flags |= POF_ENABLED;
        Py_INCREF(Py_None);
        return Py_None;
    }

调用PyEval_SetProfile设置了一个callback profiler_callback, 这样python vm在进入函数，
从函数返回前就会告诉我们::

    static int
    profiler_callback(PyObject *self, PyFrameObject *frame, int what,
                      PyObject *arg)
    {
        switch (what) {

        /* the 'frame' of a called function is about to start its execution */
        case PyTrace_CALL:
            ptrace_enter_call(self, (void *)frame->f_code,
                                   (PyObject *)frame->f_code);

            break;

        /* the 'frame' of a called function is about to finish
           (either normally or with an exception) */
        case PyTrace_RETURN:
            ptrace_leave_call(self, (void *)frame->f_code);
            break;

        /* case PyTrace_EXCEPTION:
            If the exception results in the function exiting, a
            PyTrace_RETURN event will be generated, so we don't need to
            handle it. */

    #ifdef PyTrace_C_CALL   /* not defined in Python <= 2.3 */
        /* the Python function 'frame' is issuing a call to the built-in
           function 'arg' */
        case PyTrace_C_CALL:
                ...
    #endif
        ...

最重要是PyTrace_CALL, PyTrace_RETURN这两个信号，分别表示将要进入和返回函数。
详细请参考 http://docs.python.org/release/2.6.7/c-api/init.html#PyTrace_CALL

要搞清楚ptrace_enter_call, ptrace_leave_call怎么回事，需要明白两个数据结构::

    /* represents a function or user defined block */
    typedef struct _ProfilerEntry {
        rotating_node_t header;
        PyObject *userObj; /* PyCodeObject, or a descriptive str for builtins */
        PY_LONG_LONG tt; /* total time in this entry */
        PY_LONG_LONG it; /* inline time in this entry (not in subcalls) */
        long callcount; /* how many times this was called */
        long recursivecallcount; /* how many times called recursively */
        long recursionLevel;
        rotating_node_t *calls;
    } ProfilerEntry;

    typedef struct _ProfilerContext {
        PY_LONG_LONG t0;
        PY_LONG_LONG subt;
        struct _ProfilerContext *previous;
        ProfilerEntry *ctxEntry;
    } ProfilerContext;


- ProfilerContext

  可以认为时调用堆栈链，previous指向上层调用者。存放单次计时的状态，比如进入该函数的时间t0，所有子函数耗时subt，
  这两个数据在退出函数时即Stop函数中，用来计算本次调用的tt以及it，然后累加到该函数对应的全局entry中。

- ProfilerEntry

  计时汇总信息，每个callable只对应一个entry，在这里含有所有该函数的性能数据，如
  调用次数callcount，递归调用次数recursivecallcount，当前递归深度recursionLevel，总耗时tt，去除subcall耗时之后该函数自身耗时it等


foo递归调用自己，然后又调用foo1，则上面的结构看起来如下::

    Context:                    Entry:

    foo                         foo
    foo                         foo1
    foo
    foo
    foo1    
      
开始时间，结束时间分别在initContext, Stop中获得，调用CALL_TIMER(pObj)，单位为微秒，参见 hpTimer()。

以下是在进入，退出函数时打印一些信息的patch::

    diff --git a/Modules/_lsprof.c b/Modules/_lsprof.c
    index 049c94d..53819ae 100644
    --- a/Modules/_lsprof.c
    +++ b/Modules/_lsprof.c
    @@ -319,6 +319,10 @@ static void clearEntries(ProfilerObject *pObj)
     static void
     initContext(ProfilerObject *pObj, ProfilerContext *self, ProfilerEntry *entry)
     {
    +    if (PyCode_Check(entry->userObj)){ #要进入的函数可能不是PyCodeObject类型，比如上面的PyTrace_C_CALL
    +        printf("Entering func %s\n", PyString_AS_STRING(((PyCodeObject *)entry->userObj)->co_name));
    +    }
    +
         self->ctxEntry = entry;
         self->subt = 0;
         self->previous = pObj->currentProfilerContext;
    @@ -339,17 +343,30 @@ initContext(ProfilerObject *pObj, ProfilerContext *self, ProfilerEntry *entry)
     static void
     Stop(ProfilerObject *pObj, ProfilerContext *self, ProfilerEntry *entry)
     {
    +    // Total time spent in this level of recursion of a function
         PY_LONG_LONG tt = CALL_TIMER(pObj) - self->t0;
    +    // Pure time not included sub calls
         PY_LONG_LONG it = tt - self->subt;
         if (self->previous)
             self->previous->subt += tt;   # 把本次调用的总耗时算到上一层调用者的子调用耗时里，这样上面的it=tt->self.subt就说的通了
         pObj->currentProfilerContext = self->previous;
    +
    +    // Increase the time spent  in a function after all recursion is over
         if (--entry->recursionLevel == 0)
             entry->tt += tt; # 累加 
         else
             ++entry->recursivecallcount;
    +
    +    // Increase pure time every recursion
         entry->it += it; # 累加
         entry->callcount++;
    +    double collect_factor = hpTimerUnit();
    +
    +    if (PyCode_Check(entry->userObj)){
    +        printf("Leaving func %20s  ", PyString_AS_STRING(((PyCodeObject *)entry->userObj)->co_name));
    +        printf("Timers: tt %.4f, it %.4f, nc %d, rl %d\n", entry->tt * collect_factor, 
    +            entry->it * collect_factor, entry->callcount, entry->recursionLevel);
    +    }
         if ((pObj->flags & POF_SUBCALLS) && self->previous) {
             /* find or create an entry for me in my caller's entry */
             ProfilerEntry *caller = self->previous->ctxEntry;
    @@ -441,7 +458,8 @@ profiler_callback(PyObject *self, PyFrameObject *frame, int what,
         /* the 'frame' of a called function is about to start its execution */
         case PyTrace_CALL:
             ptrace_enter_call(self, (void *)frame->f_code,
    -                                (PyObject *)frame->f_code);
    +                               (PyObject *)frame->f_code);
    +
             break;
     
         /* the 'frame' of a called function is about to finish
    @@ -593,7 +611,7 @@ static int statsForEntry(rotating_node_t *node, void *arg)
                                      entry->userObj,
                                      entry->callcount,
                                      entry->recursivecallcount,
    -                                 collect->factor * entry->tt,
    +                                 collect->factor * entry->tt, // NOTE
                                      collect->factor * entry->it,
                                      collect->sublist);
         Py_DECREF(collect->sublist);
    @@ -628,6 +646,7 @@ profiler_subentry objects:\n\
         inlinetime    inline time (not in further subcalls)\n\
     ");
     
    +
     static PyObject*
     profiler_getstats(ProfilerObject *pObj, PyObject* noarg)
     {
    20:46 jaime@oldtown Python-2.6.7 (cprofile)$ 

用来profile的测试文件， test.py::

    import time

    def foo1():
        time.sleep(1)

    def foo(n):
        foo1()
        if n > 0:
            return foo(n - 1)
        t = 1
        i = 1
        while i< 10000:
            i += 1
            t *= i
        return 42

    class A:
        def test(self):
            foo(3)

    print 'foo', id(foo)
    print 'foo1', id(foo1)

    a = A()
    print 'A.test', id(a.test)
    print 'A.test', id(A().test)
    a.test()

foo递归调用自己，每次都调用foo1。为了区别，我们在最后一次调用foo时做了一些计算，这次调用自身也消耗一些时间。profile以可执行的函数为最小单位来计算耗时，每个callable都是一个entry。class的method也是callable，具有全局唯一的地址即id，和绑定到哪个实例没有关系，只有一个entry。

output::

    20:50 jaime@oldtown Python-2.6.7 (cprofile)$ ./python.exe -m cProfile test/profile.py 
    Entering func <module>
    Entering func <module>
    Entering func A
    Leaving func                    A  Timers: tt 0.0000, it 0.0000, nc 1, rl 0
    foo 4299829448
    foo1 4299808352
    A.test 4299358368
    A.test 4299358368
    Entering func test
    Entering func foo
    Entering func foo1
    Leaving func                 foo1  Timers: tt 1.0009, it 0.0000, nc 1, rl 0
    Entering func foo
    Entering func foo1
    Leaving func                 foo1  Timers: tt 2.0021, it 0.0001, nc 2, rl 0
    Entering func foo
    Entering func foo1
    Leaving func                 foo1  Timers: tt 3.0032, it 0.0001, nc 3, rl 0
    Entering func foo
    Entering func foo1
    Leaving func                 foo1  Timers: tt 4.0043, it 0.0001, nc 4, rl 0
    Leaving func                  foo  Timers: tt 0.0000, it 0.0660, nc 1, rl 3
    Leaving func                  foo  Timers: tt 0.0000, it 0.0662, nc 2, rl 2
    Leaving func                  foo  Timers: tt 0.0000, it 0.0664, nc 3, rl 1
    Leaving func                  foo  Timers: tt 4.0708, it 0.0665, nc 4, rl 0
    Leaving func                 test  Timers: tt 4.0708, it 0.0000, nc 1, rl 0
    Leaving func             <module>  Timers: tt 4.0715, it 0.0007, nc 1, rl 0
    Leaving func             <module>  Timers: tt 4.0718, it 0.0000, nc 1, rl 0
             22 function calls (19 primitive calls) in 4.072 CPU seconds

       Ordered by: standard name

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            1    0.000    0.000    4.072    4.072 <string>:1(<module>)
            1    0.001    0.001    4.071    4.071 profile.py:1(<module>)
            1    0.000    0.000    0.000    0.000 profile.py:17(A)
            1    0.000    0.000    4.071    4.071 profile.py:18(test)
            4    0.000    0.000    4.004    1.001 profile.py:3(foo1)
          4/1    0.066    0.017    4.071    4.071 profile.py:6(foo)
            1    0.000    0.000    4.072    4.072 {execfile}
            4    0.000    0.000    0.000    0.000 {id}
            1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
            4    4.004    1.001    4.004    1.001 {time.sleep}

可以看出，每次调用foo1返回后，foo1这个entry的总耗时就加1s，foo1没有自身耗时，调用次数加1，递归深度一直为0.
而foo则不同，输出最早的那个`Leaving func foo`是最深的那次递归，递归深度rl为3，自身耗时为0.0660s，其后各次递归都没有自身耗时。当最上层foo返回即rl为0时，才计算entry foo的总耗时，为4.0708s。

对比下面的cProfile输出，可以看到tottime实际上对应于it，而不是tt，是指函数自身耗时，不包括subcall的耗时，所以可能叫inlinetime更为合适:) cumtime才是tt，函数总耗时。

Lib/cProfile.py ::

    def snapshot_stats(self):
        entries = self.getstats()
        self.stats = {}
        callersdicts = {}
        # call information
        for entry in entries:
            func = label(entry.code)
            nc = entry.callcount         # ncalls column of pstats (before '/')
            cc = nc - entry.reccallcount # ncalls column of pstats (after '/')
            tt = entry.inlinetime        # tottime column of pstats
            ct = entry.totaltime         # cumtime column of pstats

cc 为递归除外的调用次数，即4/1中的1。

statprof
~~~~~~~~~~~~~~
statprof 提供了另外一种思路。每次进行函数调用前后都执行trace操作，这算是同步的profile。如果让程序一直运行，只是定时的中断
一下，看看程序正在做什么，那么是不是可算作一种统计意义的profile？

具体做法是设置signal.SIGPROF，定时触发profile事件，在处理程序中查看当前堆栈信息，汇总之后就可大致知道程序大部分时间花在什么地方。

https://github.com/bos/statprof.py


Gevent and Gunicorn
----------------------------
gunicorn: 0.14.2, gevent: 1.0b1

gunicorn
~~~~~~~~~

gunicorn是一个WSGI server，其核心是arbiter, worker管理模型。

arbiter, 也即master进程，负责管理多个worker进程。每个worker都监听
在同一个地址上，负责处理具体的web request。这个地址可以是ip:port，
也可以是本地socket。master负责spawn，monitor, kill workers，而workers
组成一个池子， 这个进程模型非常典型。

gevent
~~~~~~

假设有greenlet F，包含三个操作A, B, C，依次顺序执行::

    greenlet F:   A -> B -> C 

如果在执行B的时候，有io数据还没就绪，则gevent会挂起当前greenlet，
转而执行别的greenlet。当发现greenlet F的io数据就绪时，会继续原来B操作。
在greenlet F看来，一切照常运行，就像阻塞了一段时间一样。这非常类似于
操作系统和进程之间的关系，当一个进程进行阻塞IO时，os挂起该进程，选择
别的进程执行，当其IO就绪后，又恢复现场继续原来的进程。
如此看来，挂起阻塞的IO，转而执行别的任务，从而使cpu不至于空等待，这也是
一个很典型的pattern。

gevent要做的事情就是patch所有的阻塞io，在其中显示调用greenlet switch，
io实际上变成异步的了，但是在greenlet内看来，结果仍是同步返回的。
如果稍有不慎，系统中仍然有遗漏的阻塞io没有patch，这个greenlet就会一直
占有cpu，导致其他greenlet无法运行，系统吞吐量则会急剧下降。

info:
串行: A, B, C 或者 A -> B -> C

并行: A | B | 或者 [A B C]

gevent(greenlet)在thread，process之外，提供了另外一种可能的并发模型。

ggevent worker
~~~~~~~~~~~~~~~~~~~
上面说到gunicorn的arbiter:worker模型，ggevent就是gunicorn支持的一种worker类型，
ggevent基于gevent，gevent基于greenlet。

http://gunicorn.org/design.html

阅读gunicorn代码请参阅 http://readthedocs.org/docs/gunicorn/en/latest/readstart.html

下面来看一下ggevent的工作流程::

    # 从Application开始
    gunicorn.app.base.WSGIApplication.run
    gunicorn.app.base.Application.run

    # 关联到一个Arbiter，启动workers
    gunicorn.arbiter.Arbiter.run
                            .manager_workers
                            .spawn_workers

    # Worker初始化
    gunicorn.workers.base.Worker.init_process
    gunicorn.workers.ggevent.GeventWorker.run:
            from gevent.pool import Pool
            from gevent.server import StreamServer

            pool = Pool(self.worker_connections)
            ...
            server = StreamServer(self.socket, handle=self.handle, spawn=pool)
            server.start()
        
Pool是gevent用来控制并发greenlet的一种机制，如果pool没有满，则pool.spawn可以立即成功，否则需要等待。 http://www.gevent.org/gevent.pool.html#gevent.pool.Pool 该参数被传递给StreamServer，用来实现并发连接数控制。

handle 参数也需注意，每个连接的具体处理，都在这个函数中完成，当server accept新连接之后，即回调此函数。

::

    gunicorn.workers.ggevent.GeventWorker.handle
    gunicorn.workers.ggevent.AsyncWorker.handle 
    gunicorn.workers.ggevent.GeventWorker.handle_request
    gunicorn.workers.ggevent.AsyncWorker.handle_request

细看handle::

    def handle(self, client, addr):
            try:
                parser = http.RequestParser(self.cfg, client)
                try:
                    while True:
                        req = None
                        with self.timeout_ctx():
                            req = parser.next()
                        if not req:
                            break
                        self.handle_request(req, client, addr)
                except StopIteration, e:
                    self.log.debug("Closing connection. %s", e)
            except socket.error, e:
                ...
            finally:
                util.close(client)

这是一个循环，从client连接中不断的读出http请求，依次处理，知道没有请求
可以读为止。这很有意思，因为它为你提供了在一个http连接中发送多个http请求
的可能性。实际上，由于client是一个普通的socket，你甚至可以不用http协议，
你可以自定义一个协议，只需将parser换成可以解析你的协议请求的parser。

pre_request, post_request钩子，具体wsgi执行都在 handle_request中。

.. note::
    
    这是一般WSGI应用的标准处理流程。和gevent worker类似的，还有一个gevent_pywsgi worker，
    它使用gevent自带的WSGI处理程序。work class为GeventPyWSGIWorker，server_class为
    gevent.pywsgi.WSGIServer，在上面创建server的时候，走的是和StreamServer不同的分支，
    在此就不深入了。

    server = self.server_class( self.socket, application=self.wsgi, spawn=pool, log=self.log, handler_class=self.wsgi_handler)
    
    application即为你的wsgi callable，handler_class则是gevent.pywsgi.WSGIHandler。        

OK, 继续看server.start的流程::

    gevent.server.StreamServer.start
    gevent.server.BaseServer.start
    gevent.server.BaseServer.start_accepting:
            if self._watcher is None:
                # just stop watcher without creating a new one?
                self._watcher = self.loop.io(self.socket.fileno(), 1)
                self._watcher.start(self._do_read)

这个watcher的作用是启动一个greenlet，利用libev来监听socket，一旦有io就调用_do_read callback，后者又调用do_handle会为每个连接启动一个新的greentlet处理::

    gevent.server.BaseServer._do_read
    gevent.server.BaseServer.do_handle

    def set_spawn(self, spawn):
        ...
        elif hasattr(spawn, 'spawn'):
            self.pool = spawn # 即上面传进来的pool参数
            self._spawn = spawn.spawn
        elif ...
        
    def do_handle(self, *args):
        spawn = self._spawn
        if spawn is None:
            self._handle(*args) # 即创建server时的handle回调函数
        else:
            spawn(self._handle, *args)

    def _do_read(self):
        for _ in xrange(self.max_accept):
            if self.full():
                self.stop_accepting()
                return
            try:
                args = self.do_read()
                self.delay = self.min_delay
                if not args:
                    return
            except:
                self.loop.handle_error(self, *sys.exc_info())
                ...
            else:
                try:
                    self.do_handle(*args)
                except:
                    self.loop.handle_error((args[1:], self), *sys.exc_info())
                    ...

_watcher.start并不是一个loop，只是spawn一个greenlet就返回了。 如果start_accepting
立即返回，start也就返回了，问：那么loop在哪里？整个server的主循环在哪里？答曰：
本来就没有loop，整个程序都是由gevent驱动greenlet的，gevent也没有loop，或者可以说,
gvent没有显式loop，整个系统是由libev的主循环驱动的::

    Unlike other network libraries and similar to eventlet, gevent starts the event 
    loop implicitly in a dedicated greenlet. There’s no reactor that you must run() or 
    dispatch() function to call. When a function from gevent API wants to block, 
    it obtains the Hub instance - a greenlet that runs the event loop - and switches to 
    it. If there’s no Hub instance yet, one is created on the fly.

http://www.gevent.org/intro.html#event-loop

更多请见下面的Hub.run。

watcher greenlet
~~~~~~~~~~~~~~~~~~

http://www.gevent.org/gevent.hub.html#module-gevent.hub

watcher.start::

    gevent.server.BaseServer:
        self.loop = gevent.get_hub().loop
        ...
        self._watcher = self.loop.io(self.socket.fileno(), 1)
        self._watcher.start(self._do_read)

    gevent.get_hub
    gevent.hub.Hub.__init__:
        loop_class = config('gevent.core.loop', 'GEVENT_LOOP')
        ...
        self.loop = loop_class(flags=loop, default=default)

gevent.core.loop在gevent/gevent/core.ppyx中定义, loop.io方法返回一个
watcher::

    gevent.core.loop.io:
        def io(self, int fd, int events, ref=True):
            return io(self, fd, events, ref)
    gevent.core.io: # 调用ev_io_init初始化fd
        libev.ev_io_init(&self._watcher, <void *>gevent_callback_io, fd, events)

watcher.start::
    gevent.core.io.start:
        self.callback = callback
        ...
        libev.ev_io_start(self.loop._ptr, &self._watcher) # 激活ev_io self._watcher

ev_io_init的回调是gevent_callback_io, 而watcher.start的回调是callback
self._do_read，这两者是怎么关联起来呢？gevent/gevent/callbacks.c::

    #define GET_OBJECT(PY_TYPE, EV_PTR, MEMBER) \
    ((struct PY_TYPE *)(((char *)EV_PTR) - offsetof(struct PY_TYPE, MEMBER)))
    ...

    #define DEFINE_CALLBACK(WATCHER_LC, WATCHER_TYPE) \
        static void gevent_callback_##WATCHER_LC(struct ev_loop *_loop, void *c_watcher, int revents) {                  \
            struct PyGevent##WATCHER_TYPE##Object* watcher = GET_OBJECT(PyGevent##WATCHER_TYPE##Object, c_watcher, _watcher);    \
            gevent_callback(watcher->loop, watcher->_callback, watcher->args, (PyObject*)watcher, c_watcher, revents); \
        }

_callback实际上就是在io.start函数中设置的callback，请参见core.ppyx中WATCHER_BASE宏定义。

ev_io_init的第一个参数，watcher._watcher，纯的裸libev.ev_io类型，当gevent_callback_io
被调用时，又被传递回来了即这个c_watcher，那么怎么找到对应的python io class对象即
watcher呢？GET_OBJECT即是答案，它可以从一个对象成员的c指针，倒推出这个对象来，强大。 

上面即是watcher.start的全部过程，get_hub自动创建了一个gevent.hub.Hub实例，一个greenlet， 整个event loop就在其Hub.run方法::

    gevent.hub.Hub.run
    gevent.core.loop.run:

        def run(self, nowait=False, once=False):
            cdef unsigned int flags = 0
            if nowait:
                flags |= libev.EVRUN_NOWAIT
            if once:
                flags |= libev.EVRUN_ONCE
            with nogil:
                libev.ev_run(self._ptr, flags)

终于，大boss出现，关于ev_run文档上这样描述::

    bool ev_run (loop, int flags)

    Finally, this is it, the event handler. This function usually is called after
    you have initialised all your watchers and you want to start handling events.
    It will ask the operating system for any new events, call the watcher
    callbacks, and then repeat the whole process indefinitely: This is why event
    loops are called loops.

http://pod.tst.eu/http://cvs.schmorp.de/libev/ev.pod

继承关系图
~~~~~~~~~~~~~~

gunicorn::

              Application
              /            \               \
      WSGIApplication  DjangoApplication   PasterBaseApplication


                   Worker
                /            \            \
            AsyncWorker     SyncWorker   TornaoWorker
               /    \            
      GeventWorker  EventletWorker


gevent::

                BaseServer
             /             \
         StreamServer     DatagramServer

         /
       WSGIServer


gunicorn reloading
~~~~~~~~~~~~~~~~~~~~~~~~
gunicorn 目前尚无自动reload机制，修改代码后需要发送SIGHUB给master进程，通知重新加载。

https://github.com/benoitc/gunicorn/issues/154

gunicorn.aribter.Arbiter init_signals 函数设置signal函数为所有信号的handler，而signal函数
只是把信号放入队列中，具体的处理统一在run函数中，这样的好处可能是降低信号handler异步执行的风险。
只有SIGCHLD信号被特殊处理。

::

    def init_signals(self):
        ...
        map(lambda s: signal.signal(s, self.signal), self.SIGNALS)
        signal.signal(signal.SIGCHLD, self.handle_chld)

    def signal(self, sig, frame):
        if len(self.SIG_QUEUE) < 5:
            self.SIG_QUEUE.append(sig)
            self.wakeup()

    def run(self):
        "Main master loop."
        self.start()
        ...
        self.manage_workers()
        while True:
            try:
                self.reap_workers()
                sig = self.SIG_QUEUE.pop(0) if len(self.SIG_QUEUE) else None
                if sig is None:
                    self.sleep()
                    self.murder_workers()
                    self.manage_workers()
                    continue
                ...
                signame = self.SIG_NAMES.get(sig)
                handler = getattr(self, "handle_%s" % signame, None)
                ...
                self.log.info("Handling signal: %s", signame)
                handler()
                self.wakeup()
                ...

    def handle_chld(self, sig, frame):
        "SIGCHLD handling"
        self.wakeup()

    def handle_hup(self):
        """\
        HUP handling.
        - Reload configuration
        - Start the new worker processes with a new configuration
        - Gracefully shutdown the old worker processes
        """
        self.log.info("Hang up: %s", self.master_name)
        self.reload()

handle_hup 负责处理HUB信号::

   def reload(self):
        ...
        # reload conf
        self.app.reload()
        self.setup(self.app)
        ...
        # spawn new workers with new app & conf
        self.cfg.on_reload(self)
        ...
        self.manage_workers()

self.app.reload在gunicorn.app.base.Application中定义，完成的工作只是重新加载app配置。

生成新的worker process是在self.cfg.on_reload，gunicorn.config::

    class OnReload(Setting):
        name = "on_reload"
        section = "Server Hooks"
        validator = validate_callable(1)
        type = "callable"
        def on_reload(server):
            for i in range(server.app.cfg.workers):
                server.spawn_worker()
        default = staticmethod(on_reload)
        desc = """\
            Called to recycle workers during a reload via SIGHUP.

            The callable needs to accept a single instance variable for the Arbiter.
            """

又生成了同样数量的worker。但是，老的worker怎么办？到此为止，好像还没有被杀掉。。。且往下看。

gunicorn.arbiter.Arbiter::

    def spawn_worker(self):
        self.worker_age += 1
        worker = self.worker_class(self.worker_age, self.pid, self.LISTENER,
                                    self.app, self.timeout/2.0,
                                    self.cfg, self.log)
        self.cfg.pre_fork(self, worker)
        pid = os.fork()
        if pid != 0:
            self.WORKERS[pid] = worker
            return pid

        # Process Child
        worker_pid = os.getpid()
        ...
 
注意worker_age这个递增id，每个master唯一，被传递给了worker_class。gunicorn.workers.base.Worker::

    class Worker(object):
        ...
        def __init__(self, age, ppid, socket, app, timeout, cfg, log):
            """\
            This is called pre-fork so it shouldn't do anything to the
            current process. If there's a need to make process wide
            changes you'll want to do that in ``self.init_process()``.
            """
            self.age = age
            ...

此时系统中有双倍的worker，下次arbiter.run循环会调用manage_worker，我们已经知道，它会保证worker数量
在可控范围之内，杀掉多余的worker, gunicorn.arbiter.Arbiter::

        def manage_workers(self):
            if len(self.WORKERS.keys()) < self.num_workers:
                self.spawn_workers()

            workers = self.WORKERS.items()
            workers.sort(key=lambda w: w[1].age)
            while len(workers) > self.num_workers:
                (pid, _) = workers.pop(0)
                self.kill_worker(pid, signal.SIGQUIT)

原来manager_workers先根据worker的age排序，然后杀掉最老的worker，这样所有发送HUB前的老worker就全被kill了，
剩下只有更新后生成的同样数量的worker，至此worker process全部完成更新。


# TODO: greenlet, libev

Worker, I will free you.

